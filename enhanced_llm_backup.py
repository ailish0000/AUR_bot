# enhanced_llm.py
import os
import requests
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv
from nlp_processor import nlp_processor, Intent, ProcessedMessage
from enhanced_vector_db import enhanced_vector_db, SearchResult

load_dotenv()

@dataclass
class ResponseContext:
    message: ProcessedMessage
    search_results: List[SearchResult]
    cached_response: Optional[str] = None

class EnhancedLLM:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENROUTER_API_KEY")
        self.api_url = "https://openrouter.ai/api/v1/chat/completions" if os.getenv("OPENROUTER_API_KEY") else "https://api.openai.com/v1/chat/completions"
        model_name = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        if "GPT-5" in model_name or "gpt-5" in model_name:
            model_name = "openai/gpt-4o-mini"  # –ë–æ–ª–µ–µ –¥–æ—Å—Ç—É–ø–Ω–∞—è –º–æ–¥–µ–ª—å
        elif "Chat" in model_name:
            model_name = "openai/gpt-3.5-turbo"
        self.model = model_name
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ —É–±—Ä–∞–Ω–∞ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ bot.py
        # self.max_response_length = 900
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.system_prompts = {
            Intent.PRODUCT_SELECTION: """
–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞. –ü–æ–º–æ–≥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ–¥–æ–±—Ä–∞—Ç—å –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –∏ –≠–§–§–ï–ö–¢–ò–í–ù–û–ï —Ä–µ—à–µ–Ω–∏–µ.

–ü–†–ê–í–ò–õ–ê –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô:
1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –ù–ò–ö–û–ì–î–ê –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∞–Ω—Ç–∏–ø–∞—Ä–∞–∑–∏—Ç–∞—Ä–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –±–µ–∑ –ø–æ–∫–∞–∑–∞–Ω–∏–π (–ï–ª–æ–º–∏–ª, –ë–í–õ, –û—Å–∏–Ω–∞ –∏ —Ç.–¥.)
3. –ü—Ä–∏ –ø—Ä–æ—Å—Ç—É–¥–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –ö–û–ú–ü–õ–ï–ö–°: –°–æ–ª–±–µ—Ä—Ä–∏ + –ë–∏—Ç–µ—Ä–æ–Ω + –ê—Ä–≥–µ–Ω—Ç, –ø–ª—é—Å –¥–ª—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞ (–í–∏—Ç–∞–º–∏–Ω –°, –ò–Ω-–ê—É—Ä–∏–Ω, –ë–ê–†–°-2)
4. –î–ª—è –ø–µ—á–µ–Ω–∏ - –≥–µ–ø–∞—Ç–æ–ø—Ä–æ—Ç–µ–∫—Ç–æ—Ä—ã (–°–∏–ª–∏—Ü–∏—Ç–∏–Ω –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å)
5. –ú–æ–∂–µ—à—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å 2-4 –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
6. –£–∫–∞–∂–∏ —Å–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏ —Å–∏–Ω–µ—Ä–≥–∏—é –ø—Ä–æ–¥—É–∫—Ç–æ–≤
7. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ò–ù–§–û–†–ú–ê–¢–ò–í–ù–´–ú –ò –ü–û–õ–ù–´–ú
8. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
   - 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–æ–¥—É–∫—Ç–∞–º
   - "–ù—É–∂–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞–∫–æ–π-—Ç–æ –∏–∑ –ø—Ä–æ–¥—É–∫—Ç–æ–≤?"
""",
            Intent.PRODUCT_INQUIRY: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –æ —Ç–æ–º –ø—Ä–æ–¥—É–∫—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –†–ê–°–°–ö–ê–ó–´–í–ê–ô –¢–û–õ–¨–ö–û –û –ó–ê–ü–†–ê–®–ò–í–ê–ï–ú–û–ú –ü–†–û–î–£–ö–¢–ï
2. –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–π –¥—Ä—É–≥–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã –±–µ–∑ –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
3. –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
4. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–æ–¥—É–∫—Ç–µ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞

–ß—Ç–æ –≤–∫–ª—é—á–∏—Ç—å:
- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ –ø–æ–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é
- –°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏ –¥–æ–∑–∏—Ä–æ–≤–∫–∞  
- –û—Å–Ω–æ–≤–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
- –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –§–æ—Ä–º–∞ –≤—ã–ø—É—Å–∫–∞

–í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
- 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ –≠–¢–û–ú–£ –ø—Ä–æ–¥—É–∫—Ç—É
- "–ü–æ–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —ç—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç?"
""",
            Intent.COMPOSITION_INQUIRY: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞. –ü–æ–¥—Ä–æ–±–Ω–æ —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–æ—Å—Ç–∞–≤–µ –ø—Ä–æ–¥—É–∫—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –û–±—ä—è—Å–Ω–∏ –ø–æ–ª—å–∑—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
3. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
4. –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ–π
5. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
6. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
7. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
   - 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
   - "–ó–∞–∫–∞–∑–∞—Ç—å —ç—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç?" (–µ—Å–ª–∏ –æ–±—Å—É–∂–¥–∞–ª—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç)
""",
            Intent.COMPLAINT: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ–¥–æ–≤–æ–ª–µ–Ω –ø—Ä–æ–¥—É–∫—Ç–æ–º.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ü—Ä–æ—è–≤–ª—è–π –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ —Å–æ—á—É–≤—Å—Ç–≤–∏–µ
2. –ü—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
3. –†–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
4. –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É
5. –ù–µ –æ–±–µ—â–∞–π —Ç–æ, —á–µ–≥–æ –Ω–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
6. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
7. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
8. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –¢–û–õ–¨–ö–û –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã", "–°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è", "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è")
""",
            Intent.GENERAL_QUESTION: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞ –ù–∞—Ç–∞–ª—å—è. –û—Ç–≤–µ—á–∞–π –Ω–∞ –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –∑–¥–æ—Ä–æ–≤—å–µ –∏ –ø—Ä–æ–¥—É–∫—Ü–∏–∏.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –†–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –µ—Å–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –µ—Å—Ç—å
3. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π
4. –£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
5. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞
6. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
7. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
8. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –¢–û–õ–¨–ö–û –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã", "–°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è", "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è")
"""
        }
    
    def _build_context(self, search_results: List[SearchResult]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        if not search_results:
            return "NO_INFORMATION_FOUND"
        
        context_parts = []
        sources = set()
        
        for result in search_results:
            chunk = result.chunk
            source = result.source
            sources.add(source)
            
            context_part = f"""
–ü—Ä–æ–¥—É–∫—Ç: {chunk.product}
–¢–∏–ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {chunk.chunk_type}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {chunk.text}
–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.score:.2f}
–ò—Å—Ç–æ—á–Ω–∏–∫: {source}
"""
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if chunk.metadata:
                if "category" in chunk.metadata:
                    context_part += f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {chunk.metadata['category']}\n"
                if "use_cases" in chunk.metadata:
                    context_part += f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: {', '.join(chunk.metadata['use_cases'][:3])}\n"
            
            context_parts.append(context_part)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources_text = f"\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {', '.join(sources)}"
        
        return "\n---\n".join(context_parts) + sources_text
    
    def _get_system_prompt(self, intent: Intent) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
        return self.system_prompts.get(intent, self.system_prompts[Intent.GENERAL_QUESTION])
    
    def _should_search_immediately(self, intent: Intent) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å—Ä–∞–∑—É –∏—Å–∫–∞—Ç—å –≤ –±–∞–∑–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
        immediate_search_intents = {
            Intent.PRODUCT_SELECTION,
            Intent.PRODUCT_INQUIRY,
            Intent.COMPOSITION_INQUIRY,
            Intent.DOSAGE_INQUIRY,
            Intent.CONTRAINDICATIONS
        }
        return intent in immediate_search_intents
    
    def _get_search_filters(self, message: ProcessedMessage) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        filters = {}
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–æ–¥—É–∫—Ç—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∏–º
        if message.entities:
            products = [entity.text for entity in message.entities if entity.label == "PRODUCT"]
            if products:
                filters["product"] = products[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç
        
        # –§–∏–ª—å—Ç—Ä—ã –ø–æ —Ç–∏–ø—É –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        if message.intent == Intent.COMPOSITION_INQUIRY:
            filters["chunk_type"] = "composition"
        elif message.intent == Intent.DOSAGE_INQUIRY:
            filters["chunk_type"] = "dosage"
        elif message.intent == Intent.CONTRAINDICATIONS:
            filters["chunk_type"] = "contraindications"
        elif message.intent == Intent.PRODUCT_SELECTION:
            # –î–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏—â–µ–º –≤ benefits –∏ description
            filters["chunk_type"] = ["benefits", "description"]
        
        return filters if filters else None
    
    def process_query(self, user_text: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # 0. –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ small-talk –±–µ–∑ –ø–æ–∏—Å–∫–∞
            smalltalk = user_text.strip().lower()
            if smalltalk in {"–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä"}:
                return (
                    "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Å –ø–æ–¥–±–æ—Ä–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ê–≤—Ä–æ—Ä—ã. "
                    "–°–ø—Ä–æ—Å–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä: '–û—Ç –ø—Ä–æ—Å—Ç—É–¥—ã', '–î–ª—è –ø–µ—á–µ–Ω–∏', '–°–æ—Å—Ç–∞–≤ –°–æ–ª–±–µ—Ä—Ä–∏-H', '–ö–∞–∫ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ë–∏—Ç–µ—Ä–æ–Ω-H'."
                )
            if smalltalk in {"–∫–∞–∫ –¥–µ–ª–∞?", "–∫–∞–∫ –¥–µ–ª–∞", "–∫–∞–∫ —Ç—ã?", "–∫–∞–∫ —Ç—ã"}:
                return (
                    "–°–ø–∞—Å–∏–±–æ, –≤—Å–µ –æ—Ç–ª–∏—á–Ω–æ –∏ —è –≥–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å! –û–ø–∏—à–∏ –ø—Ä–æ–±–ª–µ–º—É –∏–ª–∏ —Å–ø—Ä–æ—Å–∏ –ø—Ä–æ –ø—Ä–æ–¥—É–∫—Ç."
                )
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached_response = enhanced_vector_db.get_cached_response(user_text)
            if cached_response:
                return f"{cached_response}\n\nüí° _–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∫—ç—à–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞_"
            
            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ NLP
            processed_message = nlp_processor.process_message(user_text)
            
            # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞
            search_results = []
            
            if self._should_search_immediately(processed_message.intent):
                # –°—Ä–∞–∑—É –∏—â–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ
                filters = self._get_search_filters(processed_message)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
                search_query = processed_message.expanded_query
                search_results = enhanced_vector_db.search(
                    query=search_query,
                    filters=filters,
                    limit=3
                )
                
                # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã, –∏—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                if processed_message.entities:
                    for entity in processed_message.entities:
                        if entity.label == "PRODUCT":
                            product_results = enhanced_vector_db.search_by_product(
                                entity.text, limit=2
                            )
                            search_results.extend(product_results)
            
            # 4. –ï—Å–ª–∏ –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ –∏–ª–∏ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—â–µ–º –ø–æ —Å–ª—É—á–∞—é –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
            if not search_results and processed_message.intent in [
                Intent.GENERAL_QUESTION, Intent.PRODUCT_SELECTION
            ]:
                search_results = enhanced_vector_db.search_by_use_case(
                    processed_message.expanded_query, limit=3
                )
            
            # 5. –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –¥–µ–ª–∞–µ–º –æ–±—â–∏–π –ø–æ–∏—Å–∫
            if not search_results:
                search_results = enhanced_vector_db.search(
                    processed_message.expanded_query, limit=2
                )

            # 5.1. –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤—Å–µ–≥–¥–∞ –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –¥–ª—è –õ–Æ–ë–´–• –∑–∞–ø—Ä–æ—Å–æ–≤ 
            local_context = self._build_local_kb_context(processed_message.expanded_query)
            if local_context:
                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM (–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞)
                local_info = self._build_context_from_local(local_context)
                if local_info and local_info != "NO_INFORMATION_FOUND":
                    context = local_info
                    print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {local_context.count('–ü—Ä–æ–¥—É–∫—Ç: ')})")
                # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback –æ—Ç–≤–µ—Ç
                if not self.api_key:
                    provisional = self._fallback_response(local_context)
                    return provisional
            
            # 6. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            if 'context' not in locals() or not context:
                context = self._build_context(search_results)
            
            # 6.1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if context == "NO_INFORMATION_FOUND":
                # –°–æ–∑–¥–∞–µ–º –≤–µ–∂–ª–∏–≤—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É
                response = (
                    "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n\n"
                    "üí° –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç:\n"
                    "‚Ä¢ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
                    "‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞\n"
                    "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É\n\n"
                    "‚úâÔ∏è –ù–∞–ø–∏—à–∏—Ç–µ –ù–∞—Ç–∞–ª—å–µ ‚Äî –æ–Ω–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–º–æ–∂–µ—Ç!"
                )
                return response
            
            # 7. –ï—Å–ª–∏ —ç—Ç–æ –∂–∞–ª–æ–±–∞ —Å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é, –¥–æ–±–∞–≤–ª—è–µ–º –æ—Å–æ–±—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            if (processed_message.intent == Intent.COMPLAINT or 
                processed_message.sentiment == "negative"):
                context += "\n\n–í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã—Ä–∞–∂–∞–µ—Ç –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ. –ù—É–∂–Ω–æ –ø—Ä–æ—è–≤–∏—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ."
            
            # 8. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            response = self._ask_llm(
                processed_message.text,
                context,
                processed_message.intent
            )
            
            # 9. –ö—ç—à–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            if len(user_text.strip()) > 20:  # –ö—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                enhanced_vector_db.cache_response(user_text, response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

    def _build_local_kb_context(self, expanded_query: str) -> Optional[str]:
        """–ü—Ä–æ—Å—Ç–æ–π –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ knowledge_base.json –∏ knowledge_base_new.json –±–µ–∑ Qdrant"""
        try:
            import json
            # –ò—â–µ–º –ø–æ –ª—é–±–æ–º—É —Å–ª–æ–≤—É –¥–ª–∏–Ω–æ–π –±–æ–ª—å—à–µ 1 —Å–∏–º–≤–æ–ª–∞
            terms = [t.strip().lower() for t in expanded_query.split() if len(t.strip()) > 1]
            if not terms:
                return None
            
            matches = []
            found_products = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤
            
            # –ü–æ–∏—Å–∫ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            try:
                with open("knowledge_base.json", "r", encoding="utf-8") as f:
                    kb_main = json.load(f)
                matches.extend(self._search_in_kb(kb_main, terms, "knowledge_base.json", found_products))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è knowledge_base.json: {e}")
            
            # –ü–æ–∏—Å–∫ –≤ –Ω–æ–≤–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            try:
                with open("knowledge_base_new.json", "r", encoding="utf-8") as f:
                    kb_new = json.load(f)
                matches.extend(self._search_in_kb(kb_new, terms, "knowledge_base_new.json", found_products))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è knowledge_base_new.json: {e}")
            
            if matches:
                return "\n---\n".join(matches)
            return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ _build_local_kb_context: {e}")
            return None
    
    def _build_context_from_local(self, local_context: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è LLM"""
        if not local_context:
            return "NO_INFORMATION_FOUND"
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è LLM
        lines = local_context.split('\n')
        products = []
        current_product = {}
        
        for line in lines:
            if line.startswith('–ü—Ä–æ–¥—É–∫—Ç: '):
                if current_product:
                    products.append(current_product)
                current_product = {'name': line.replace('–ü—Ä–æ–¥—É–∫—Ç: ', '').strip()}
            elif line.startswith('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: '):
                current_product['category'] = line.replace('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: ', '').strip()
            elif line.startswith('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '):
                current_product['description'] = line.replace('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: ', '').strip()
        
        if current_product:
            products.append(current_product)
        
        if not products:
            return "NO_INFORMATION_FOUND"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è LLM
        formatted_chunks = []
        for product in products:
            chunk = f"–ü—Ä–æ–¥—É–∫—Ç: {product['name']}\n"
            if 'category' in product:
                chunk += f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product['category']}\n"
            if 'description' in product:
                chunk += f"–û–ø–∏—Å–∞–Ω–∏–µ: {product['description']}\n"
            formatted_chunks.append(chunk)
        
        return "\n---\n".join(formatted_chunks)

    def _search_in_kb(self, kb_data: list, terms: list, source: str, found_products: set) -> list:
        """–ü–æ–∏—Å–∫ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        matches = []
        for item in kb_data:
            product = item.get("product", "")
            product_id = item.get("id", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ø–æ–ª—è –Ω–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤
            searchable_fields = {
                "product": item.get("product", ""),
                "description": item.get("description", ""),
                "short_description": item.get("short_description", ""),
                "benefits": "; ".join(item.get("benefits", [])),
                "short_benefits": "; ".join(item.get("short_benefits", [])),
                "composition": item.get("composition", ""),
                "dosage": item.get("dosage", ""),
                "contraindications": item.get("contraindications", ""),
                "category": item.get("category", ""),
            }
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance_score = 0
            matching_fields = []
            
            for field_name, field_text in searchable_fields.items():
                if field_text:
                    matches_in_field = sum(1 for term in terms if term in field_text.lower())
                    if matches_in_field > 0:
                        matching_fields.append(field_name)
                        # –ë–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –≤–µ—Å –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π
                        if field_name in ["product", "short_description", "benefits"]:
                            relevance_score += matches_in_field * 2
                        else:
                            relevance_score += matches_in_field
            
            if relevance_score > 0 and product_id not in found_products:
                found_products.add(product_id)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ
                category = item.get("category", "")
                form = item.get("form", "")
                short_desc = item.get("short_description", "")
                
                part = (
                    f"–ü—Ä–æ–¥—É–∫—Ç: {product}\n"
                    f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n"
                    f"–§–æ—Ä–º–∞: {form}\n"
                    f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {short_desc}\n"
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {min(0.95, 0.50 + relevance_score * 0.1):.2f}\n"
                    f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source}\n"
                )
                matches.append((relevance_score, part))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-10
        matches.sort(key=lambda x: x[0], reverse=True)
        return [match[1] for match in matches[:10]]
    
    def _ask_llm(self, question: str, context: str, intent: Intent) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenAI API"""
        if not self.api_key:
            return self._fallback_response(context)
        
        system_prompt = self._get_system_prompt(intent)
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n{context}\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}"
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                answer = result["choices"][0]["message"]["content"]
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Markdown –≤ HTML –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                answer = self._convert_markdown_to_html(answer)
                
                # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ø–æ–¥–ø–∏—Å—å LLM –Ω–∞ –Ω–∞—à—É
                import re
                answer = re.sub(r'\(–ò—Å—Ç–æ—á–Ω–∏–∫:.*?\)', '', answer)
                answer = answer.strip()
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à—É –ø–æ–¥–ø–∏—Å—å
                answer += "\n\nüìö –î–∞–Ω–Ω—ã–µ –∏–∑ —Å–∞–π—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞"
                
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —É–±—Ä–∞–Ω–æ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ bot.py
                # answer = self._limit_response_length(answer)
                
                return answer
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API ({response.status_code}): {response.text[:200]}")
                return self._fallback_response(context)
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {e}")
            return self._fallback_response(context)
    
    def _convert_markdown_to_html(self, text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Markdown —Ä–∞–∑–º–µ—Ç–∫—É –≤ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ HTML —Ç–µ–≥–æ–≤"""
        import re
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º **text** –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏)
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º *text* –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º `text` –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏)
        text = re.sub(r'`(.*?)`', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º _text_ –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
        text = re.sub(r'_(.*?)_', r'\1', text)
        
        return text
    
    def _generate_follow_up_questions(self, products_info: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
        if not products_info:
            return ""
        
        questions = []
        
        for product_name in products_info.keys():
            product_lower = product_name.lower()
            
            # –í–æ–ø—Ä–æ—Å—ã –æ —Å–æ—Å—Ç–∞–≤–µ
            if "—Å–æ–ª–±–µ—Ä—Ä–∏" in product_lower or "–æ–±–ª–µ–ø–∏—Ö" in product_lower:
                questions.extend([
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–ª—å–∑–µ –æ–±–ª–µ–ø–∏—Ö–∏",
                    "‚Ä¢ –ö–∞–∫–∏–µ –≤–∏—Ç–∞–º–∏–Ω—ã —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–ª–µ–ø–∏—Ö–∞?",
                    "‚Ä¢ –ö–∞–∫ –æ–±–ª–µ–ø–∏—Ö–∞ —É–∫—Ä–µ–ø–ª—è–µ—Ç –∏–º–º—É–Ω–∏—Ç–µ—Ç?"
                ])
            elif "–±–∏—Ç–µ—Ä–æ–Ω" in product_lower or "—Å–≤–µ–∫–ª" in product_lower:
                questions.extend([
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–ª—å–∑–µ —Å–≤–µ–∫–ª—ã",
                    "‚Ä¢ –ö–∞–∫ —Å–≤–µ–∫–ª–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫—Ä–æ–≤—å?",
                    "‚Ä¢ –ö–∞–∫–∏–µ –≤–µ—â–µ—Å—Ç–≤–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–≤–µ–∫–ª–∞?"
                ])
            elif "–∞—Ä–≥–µ–Ω—Ç" in product_lower or "—Å–µ—Ä–µ–±—Ä" in product_lower:
                questions.extend([
                    "‚Ä¢ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–µ—Ä–µ–±—Ä–æ –ø—Ä–æ—Ç–∏–≤ –±–∞–∫—Ç–µ—Ä–∏–π?",
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Å–µ—Ä–µ–±—Ä–∞",
                    "‚Ä¢ –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ª–∏ —Å–µ—Ä–µ–±—Ä–æ –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–º–∞?"
                ])
            
            # –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–¥—É–∫—Ç–µ
            questions.extend([
                f"‚Ä¢ –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Å–æ—Å—Ç–∞–≤–µ {product_name}",
                f"‚Ä¢ –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–Ω–∏–º–∞—Ç—å {product_name}?",
                f"‚Ä¢ –ï—Å—Ç—å –ª–∏ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è —É {product_name}?",
                f"‚Ä¢ –ú–æ–∂–Ω–æ –ª–∏ —Å–æ—á–µ—Ç–∞—Ç—å {product_name} —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏?"
            ])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_questions = list(dict.fromkeys(questions))[:6]
        
        if unique_questions:
            return (
                "\n\nüí° –ú–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ:\n" + 
                "\n".join(unique_questions) +
                "\n\nüí¨ –ü—Ä–æ—Å—Ç–æ —Å–ø—Ä–æ—Å–∏!"
            )
        
        return ""

    def _fallback_response(self, context: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
        if not context or context == "NO_INFORMATION_FOUND" or "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞" in context:
            response = (
                "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n\n"
                "üí° –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç:\n"
                "‚Ä¢ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
                "‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞\n"
                "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É\n\n"
                "‚úâÔ∏è –ù–∞–ø–∏—à–∏—Ç–µ –ù–∞—Ç–∞–ª—å–µ ‚Äî –æ–Ω–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–º–æ–∂–µ—Ç!"
            )
            return response
        
        # –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö
        lines = context.split('\n')
        products = []
        current_product = {}
        
        for line in lines:
            if line.startswith('–ü—Ä–æ–¥—É–∫—Ç: '):
                if current_product:
                    products.append(current_product)
                current_product = {'name': line.replace('–ü—Ä–æ–¥—É–∫—Ç: ', '').strip()}
            elif line.startswith('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: '):
                current_product['category'] = line.replace('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: ', '').strip()
            elif line.startswith('–§–æ—Ä–º–∞: '):
                current_product['form'] = line.replace('–§–æ—Ä–º–∞: ', '').strip()
            elif line.startswith('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '):
                current_product['description'] = line.replace('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: ', '').strip()
        
        if current_product:
            products.append(current_product)
        
        if not products:
            return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –≤—ã–±–æ—Ä–∞
        if len(products) == 1:
            product = products[0]
            response = f"üåø **{product['name']}**\n\n"
            if 'category' in product:
                response += f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product['category']}\n"
            if 'form' in product:
                response += f"üíä –§–æ—Ä–º–∞: {product['form']}\n"
            if 'description' in product:
                response += f"üìù {product['description']}\n\n"
            response += "üí° –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —Å–æ—Å—Ç–∞–≤–µ, —Å–ø–æ—Å–æ–±–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        else:
            response = f"üîç –ù–∞–π–¥–µ–Ω–æ **{len(products)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤** –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É:\n\n"
            
            for i, product in enumerate(products, 1):
                response += f"**{i}. {product['name']}**\n"
                if 'category' in product:
                    response += f"   üìÇ {product['category']}\n"
                if 'form' in product:
                    response += f"   üíä {product['form']}\n"
                if 'description' in product:
                    response += f"   üìù {product['description'][:100]}...\n"
                response += "\n"
            
            response += "üí° **–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–¥—É–∫—Ç –∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–º:**\n"
            response += "‚Ä¢ –°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n"
            response += "‚Ä¢ –°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n"
            response += "‚Ä¢ –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è\n"
            response += "‚Ä¢ –ü–æ–ª–µ–∑–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞"
        
        return response

    def _limit_response_length(self, response: str, max_length: int = None) -> str:
        """–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
        # –ú–µ—Ç–æ–¥ –æ—Ç–∫–ª—é—á–µ–Ω - –≤—Å—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–µ–∑–∞–Ω–∏—è —Ç–µ–ø–µ—Ä—å –≤ bot.py
        return response

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
enhanced_llm = EnhancedLLM()
