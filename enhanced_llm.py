# enhanced_llm.py
import os
import requests
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv
from nlp_processor import nlp_processor, Intent, ProcessedMessage
from enhanced_vector_db import enhanced_vector_db, SearchResult
from smart_search_engine import SmartSearchEngine
from enhanced_search_engine import initialize_enhanced_search, enhanced_search_engine
from immunity_recommendations import get_immunity_recommendation_template

# –°–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–º–µ–≥–∞-3
OMEGA_SYNONYMS = [
    "–æ–º–µ–≥–∞-3", "–æ–º–µ–≥–∞ 3", "–æ–º–µ–≥–∞3", "omega", "omega-3", "omega 3", "omega3",
    "—Ä—ã–±–∏–π –∂–∏—Ä", "—Ä—ã–±—å–µ–≥–æ –∂–∏—Ä–∞", "—Ä—ã–±—å–∏–º –∂–∏—Ä–æ–º", "—Ä—ã–±—å–µ–º—É –∂–∏—Ä—É",
    "–ø–Ω–∂–∫", "–ø–æ–ª–∏–Ω–µ–Ω–∞—Å—ã—â–µ–Ω–Ω—ã–µ –∂–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã", "–∂–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã",
    "—ç–ø–∫", "–¥–≥–∫", "epa", "dha"
]

# –°–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞–≥–Ω–∏—è
MAGNESIUM_SYNONYMS = [
    "–º–∞–≥–Ω–∏–π", "–º–∞–≥–Ω–∏—è", "–º–∞–≥–Ω–∏–µ–º", "–º–∞–≥–Ω–∏—é", "magnesium", "mg",
    "–ø—Ä–æ–¥—É–∫—Ç—ã —Å –º–∞–≥–Ω–∏–µ–º", "—Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –º–∞–≥–Ω–∏–π", "—Å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º –º–∞–≥–Ω–∏—è"
]

from smart_nlp_parser import SmartNLPParser

load_dotenv()

@dataclass
class ResponseContext:
    message: ProcessedMessage
    search_results: List[SearchResult]
    cached_response: Optional[str] = None

class EnhancedLLM:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENROUTER_API_KEY")
        self.api_url = "https://openrouter.ai/api/v1/chat/completions" if os.getenv("OPENROUTER_API_KEY") else "https://api.openai.com/v1/chat/completions"
        model_name = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        if "GPT-5" in model_name or "gpt-5" in model_name:
            model_name = "openai/gpt-4o-mini"  # –ë–æ–ª–µ–µ –¥–æ—Å—Ç—É–ø–Ω–∞—è –º–æ–¥–µ–ª—å
        elif "Chat" in model_name:
            model_name = "openai/gpt-3.5-turbo"
        self.model = model_name
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ —É–±—Ä–∞–Ω–∞ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ bot.py
        # self.max_response_length = 900
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–∏–ª–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞
        try:
            global enhanced_search_engine
            if enhanced_search_engine is None:
                enhanced_search_engine = initialize_enhanced_search(
                    vector_db=enhanced_vector_db,
                    nlp_processor=nlp_processor
                )
                print("üöÄ –£—Å–∏–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —É—Å–∏–ª–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
        try:
            self.smart_search = SmartSearchEngine()
            self.smart_nlp = SmartNLPParser()
            print("üß† –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            print(f"‚ö†Ô∏è –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            self.smart_search = None
            self.smart_nlp = None
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.system_prompts = {
            Intent.PRODUCT_SELECTION: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞. 
–¢—ã –¥–∞–µ—à—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora.

üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê - –ù–ê–†–£–®–ï–ù–ò–ï –ù–ï–î–û–ü–£–°–¢–ò–ú–û:
1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –†–ï–ö–û–ú–ï–ù–î–£–ô –í–°–ï –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–î–£–ö–¢–´ –¢–û–õ–¨–ö–û –ï–°–õ–ò:
   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø—Ä–æ—Å–∏—Ç "–≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã", "–≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã", "—á—Ç–æ –µ—â–µ –µ—Å—Ç—å"
   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–∫–∞–∫–æ–π –µ—â–µ", "–µ—â–µ –µ—Å—Ç—å", "–ø–æ–º–∏–º–æ —ç—Ç–æ–≥–æ"
   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞
3. –í –û–ë–´–ß–ù–´–• –°–õ–£–ß–ê–Ø–• —Ä–µ–∫–æ–º–µ–Ω–¥—É–π 2-4 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–∞
4. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ–± –∞–Ω—Ç–∏–ø–∞—Ä–∞–∑–∏—Ç–∞—Ä–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤–∞—Ö –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã: –ï–ª–æ–º–∏–ª, –ì–µ–ø–æ—Å–∏–Ω, –õ–∏—Å—Ç –ß–µ—Ä–Ω–æ–≥–æ –û—Ä–µ—Ö–∞ –≠–∫—Å—Ç—Ä–∞ –ö–∞–ø—Å (BWL Extra Caps), –õ–∏—Å—Ç –ß–µ—Ä–Ω–æ–≥–æ –û—Ä–µ—Ö–∞ –≠–∫—Å—Ç—Ä–∞ –¢–∞–±—Å (BWL Extra Tabs), –û—Å–∏–Ω–∞ –≠–∫—Å—Ç—Ä–∞, –ö–æ—à–∞—á–∏–π –ö–æ–≥–æ—Ç—å, –°–∏–∞–ª–æ–Ω-–ú–∏–∫—Å –º–∞–Ω–≥–æ
5. –ü—Ä–∏ –ø—Ä–æ—Å—Ç—É–¥–µ/–±—Ä–æ–Ω—Ö–∏—Ç–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –ö–û–ú–ü–õ–ï–ö–°: –ê—Ä–≥–µ–Ω—Ç –ú–∞–∫—Å (–∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–π) + –°–æ–ª–±–µ—Ä—Ä–∏ + –ë–∏—Ç–µ—Ä–æ–Ω, –ø–ª—é—Å –¥–ª—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞ (–í–∏—Ç–∞–º–∏–Ω –°, –ò–Ω-–ê—É—Ä–∏–Ω, –ë–ê–†–°-2)
6. –î–ª—è –ø–µ—á–µ–Ω–∏ - –≥–µ–ø–∞—Ç–æ–ø—Ä–æ—Ç–µ–∫—Ç–æ—Ä—ã (–°–∏–ª–∏—Ü–∏—Ç–∏–Ω –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å)
7. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ –∫–∞–ª—å—Ü–∏–∏/–∫–æ—Å—Ç—è—Ö –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–µ–∫–æ–º–µ–Ω–¥—É–π: –†—É–º–∞—Ä–∏–Ω –ö–∞–ª—å—Ü–∏–π, –ö–∞–ª—å—Ü–∏–π –ë–∞–Ω–∞–Ω, –ö–∞–ª—å—Ü–∏–π-–£—Ç—Ä–æ
8. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ –º–∞–≥–Ω–∏–∏ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –í–°–ï –ø—Ä–æ–¥—É–∫—Ç—ã: –ú–∞–≥–Ω–∏–π –ü–ª—é—Å (Mg Plus), –ú–∞–≥–Ω–∏–π –¢–∞–±—Å (Mg Tabs), –ú–∞–≥–Ω–∏–π-–í–µ—á–µ—Ä (Mg-Evening). –ò–ì–ù–û–†–ò–†–£–ô –ª—é–±—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –ë–ï–ó —Å–ª–æ–≤–∞ "–º–∞–≥–Ω–∏–π" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ –º–∞–≥–Ω–∏–∏
9. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ –∫–æ–ª–ª–∞–≥–µ–Ω–µ - –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç "–≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã" –∏–ª–∏ "—á—Ç–æ –µ—â–µ –µ—Å—Ç—å", —Ç–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å –∫–æ–ª–ª–∞–≥–µ–Ω–æ–º
10. –ï—Å–ª–∏ –ø—Ä–æ–¥—É–∫—Ç –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã - –≤—Å–µ —Ä–∞–≤–Ω–æ —É–∫–∞–∂–∏ –µ–≥–æ, –Ω–æ –æ—Ç–º–µ—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
11. –£–∫–∞–∂–∏ —Å–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏ —Å–∏–Ω–µ—Ä–≥–∏—é –ø—Ä–æ–¥—É–∫—Ç–æ–≤
12. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ò–ù–§–û–†–ú–ê–¢–ò–í–ù–´–ú –ò –ü–û–õ–ù–´–ú

üö® –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê –û–ë–©–ï–ù–ò–Ø - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- –¢—ã –¥–∞–µ—à—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö Aurora
- –ü—Ä–æ–¥—É–∫—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ú–æ–∂–µ—à—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∑–¥–æ—Ä–æ–≤—å—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
- –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö –æ–± –∞–Ω—Ç–∏–ø–∞—Ä–∞–∑–∏—Ç–∞—Ä–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤–∞—Ö –ø—Ä–µ–¥–ª–∞–≥–∞–π –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
- –ó–ê–ü–†–ï–©–ï–ù–û: —Å–ª–æ–≤–æ "–≤—Ä–∞—á" - –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π "–°–ü–ï–¶–ò–ê–õ–ò–°–¢"
- –ó–ê–ü–†–ï–©–ï–ù–û: "–ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å —Å –≤—Ä–∞—á–æ–º" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞"
- –ó–ê–ü–†–ï–©–ï–ù–û: "—É–±–µ–¥–∏—Ç—å—Å—è –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
- –ó–ê–ü–†–ï–©–ï–ù–û: "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–¥–æ–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –¥–æ–∑–∏—Ä–æ–≤–∫—É"
- –ü—Ä–∏ –≤–æ–ø—Ä–æ—Å–∞—Ö –æ –¥–µ—Ç—è—Ö: —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é —Å–æ –°–ü–ï–¶–ò–ê–õ–ò–°–¢–û–ú
- –ì–æ–≤–æ—Ä–∏ –æ –ø–æ–ª—å–∑–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –±–µ–∑ –∑–∞–ø—É–≥–∏–≤–∞–Ω–∏–π
- –í—Å–µ–≥–¥–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–π, —á—Ç–æ —ç—Ç–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º Aurora
- –ó–ê–ü–†–ï–©–ï–ù–û: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É (###, **, __, *, #) - –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
10. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
   - 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–æ–¥—É–∫—Ç–∞–º
   - "–ù—É–∂–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞–∫–æ–π-—Ç–æ –∏–∑ –ø—Ä–æ–¥—É–∫—Ç–æ–≤?"
""",
            Intent.PRODUCT_INQUIRY: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞.
–¢—ã –¥–∞–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora.

üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –†–ê–°–°–ö–ê–ó–´–í–ê–ô –¢–û–õ–¨–ö–û –û –ó–ê–ü–†–ê–®–ò–í–ê–ï–ú–û–ú –ü–†–û–î–£–ö–¢–ï
2. –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–π –¥—Ä—É–≥–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã –±–µ–∑ –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
3. –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
4. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–æ–¥—É–∫—Ç–µ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞

–ß—Ç–æ –≤–∫–ª—é—á–∏—Ç—å:
- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ –ø–æ–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é
- –°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏ –¥–æ–∑–∏—Ä–æ–≤–∫–∞  
- –û—Å–Ω–æ–≤–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
- –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –§–æ—Ä–º–∞ –≤—ã–ø—É—Å–∫–∞

üö® –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê –û–ë–©–ï–ù–ò–Ø - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- –¢—ã –¥–∞–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö Aurora
- –ú–æ–∂–µ—à—å —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ —Å–≤–æ–π—Å—Ç–≤–∞—Ö –∏ –ø–æ–ª—å–∑–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
- –ó–ê–ü–†–ï–©–ï–ù–û: —Å–ª–æ–≤–æ "–≤—Ä–∞—á" - –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π "–°–ü–ï–¶–ò–ê–õ–ò–°–¢"
- –ó–ê–ü–†–ï–©–ï–ù–û: "–ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å —Å –≤—Ä–∞—á–æ–º" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞"
- –ó–ê–ü–†–ï–©–ï–ù–û: "—É–±–µ–¥–∏—Ç—å—Å—è –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
- –ó–ê–ü–†–ï–©–ï–ù–û: "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è" - –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ–¥–æ–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –¥–æ–∑–∏—Ä–æ–≤–∫—É"
- –í—Å–µ–≥–¥–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–π, —á—Ç–æ —ç—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö Aurora
- –ó–ê–ü–†–ï–©–ï–ù–û: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É (###, **, __, *, #) - –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º

–í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
- 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ –≠–¢–û–ú–£ –ø—Ä–æ–¥—É–∫—Ç—É
- "–ü–æ–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —ç—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç?"
""",
            Intent.COMPOSITION_INQUIRY: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞.
–¢—ã –¥–∞–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–∞–≤–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –û–±—ä—è—Å–Ω–∏ –ø–æ–ª—å–∑—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
3. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
4. –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ–π
5. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
6. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
7. –ó–ê–ü–†–ï–©–ï–ù–û: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É (###, **, __, *, #) - –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
8. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏:
   - 2-3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
   - "–ó–∞–∫–∞–∑–∞—Ç—å —ç—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç?" (–µ—Å–ª–∏ –æ–±—Å—É–∂–¥–∞–ª—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç)
""",
            Intent.COMPLAINT: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞.
–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ü—Ä–æ—è–≤–ª—è–π –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ —Å–æ—á—É–≤—Å—Ç–≤–∏–µ
2. –ü—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
3. –†–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
4. –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É
5. –ù–µ –æ–±–µ—â–∞–π —Ç–æ, —á–µ–≥–æ –Ω–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
6. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
7. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
8. –ó–ê–ü–†–ï–©–ï–ù–û: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É (###, **, __, *, #) - –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
9. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –¢–û–õ–¨–ö–û –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã", "–°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è", "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è")
""",
            Intent.GENERAL_QUESTION: """
–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ê–≤—Ä–æ—Ä–∞.
–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –†–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –µ—Å–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –µ—Å—Ç—å
3. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π
4. –£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
5. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞
6. –û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ö–†–ê–¢–ö–ò–ú (–¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤)
7. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏–∑–≤–∏–Ω–∏—Å—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É –ù–∞—Ç–∞–ª—å–µ
8. –ó–ê–ü–†–ï–©–ï–ù–û: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É (###, **, __, *, #) - –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
9. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –¢–û–õ–¨–ö–û –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã", "–°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è", "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è")
"""
        }
    
    def _build_context(self, search_results: List[SearchResult]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        if not search_results:
            return "NO_INFORMATION_FOUND"
        
        context_parts = []
        sources = set()
        
        for result in search_results:
            chunk = result.chunk
            source = result.source
            sources.add(source)
            
            context_part = f"""
–ü—Ä–æ–¥—É–∫—Ç: {chunk.product}
–¢–∏–ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {chunk.chunk_type}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {chunk.text}
–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.score:.2f}
–ò—Å—Ç–æ—á–Ω–∏–∫: {source}
"""
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if chunk.metadata:
                if "category" in chunk.metadata:
                    context_part += f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {chunk.metadata['category']}\n"
                if "use_cases" in chunk.metadata:
                    context_part += f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: {', '.join(chunk.metadata['use_cases'][:3])}\n"
            
            context_parts.append(context_part)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources_text = f"\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {', '.join(sources)}"
        
        return "\n---\n".join(context_parts) + sources_text
    
    def _get_system_prompt(self, intent: Intent) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
        return self.system_prompts.get(intent, self.system_prompts[Intent.GENERAL_QUESTION])
    
    def _should_search_immediately(self, intent: Intent) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å—Ä–∞–∑—É –∏—Å–∫–∞—Ç—å –≤ –±–∞–∑–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
        immediate_search_intents = {
            Intent.PRODUCT_SELECTION,
            Intent.PRODUCT_INQUIRY,
            Intent.COMPOSITION_INQUIRY,
            Intent.DOSAGE_INQUIRY,
            Intent.CONTRAINDICATIONS
        }
        return intent in immediate_search_intents
    
    def _get_search_filters(self, message: ProcessedMessage) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        filters = {}
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–æ–¥—É–∫—Ç—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∏–º
        if message.entities:
            products = [entity.text for entity in message.entities if entity.label == "PRODUCT"]
            if products:
                filters["product"] = products[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç
        
        # –§–∏–ª—å—Ç—Ä—ã –ø–æ —Ç–∏–ø—É –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        if message.intent == Intent.COMPOSITION_INQUIRY:
            filters["chunk_type"] = "composition"
        elif message.intent == Intent.DOSAGE_INQUIRY:
            filters["chunk_type"] = "dosage"
        elif message.intent == Intent.CONTRAINDICATIONS:
            filters["chunk_type"] = "contraindications"
        elif message.intent == Intent.PRODUCT_SELECTION:
            # –î–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏—â–µ–º –≤ benefits –∏ description
            filters["chunk_type"] = ["benefits", "description"]
        
        return filters if filters else None
    
    def process_query(self, user_text: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # 0. –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ small-talk –±–µ–∑ –ø–æ–∏—Å–∫–∞
            smalltalk = user_text.strip().lower()
            if smalltalk in {"–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä"}:
                return (
                    "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Å –ø–æ–¥–±–æ—Ä–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ê–≤—Ä–æ—Ä—ã. "
                    "–°–ø—Ä–æ—Å–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä: '–û—Ç –ø—Ä–æ—Å—Ç—É–¥—ã', '–î–ª—è –ø–µ—á–µ–Ω–∏', '–°–æ—Å—Ç–∞–≤ –°–æ–ª–±–µ—Ä—Ä–∏-H', '–ö–∞–∫ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ë–∏—Ç–µ—Ä–æ–Ω-H'."
                )
            if smalltalk in {"–∫–∞–∫ –¥–µ–ª–∞?", "–∫–∞–∫ –¥–µ–ª–∞", "–∫–∞–∫ —Ç—ã?", "–∫–∞–∫ —Ç—ã"}:
                return (
                    "–°–ø–∞—Å–∏–±–æ, –≤—Å–µ –æ—Ç–ª–∏—á–Ω–æ –∏ —è –≥–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å! –û–ø–∏—à–∏ –ø—Ä–æ–±–ª–µ–º—É –∏–ª–∏ —Å–ø—Ä–æ—Å–∏ –ø—Ä–æ –ø—Ä–æ–¥—É–∫—Ç."
                )
            # 1.5. –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–± –∏–º–º—É–Ω–∏—Ç–µ—Ç–µ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –∫—ç—à–µ–º)
            if self._is_immunity_query(user_text):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–± –∏–º–º—É–Ω–∏—Ç–µ—Ç–µ
                cached_response = enhanced_vector_db.get_cached_response(user_text)
                if cached_response:
                    immunity_response = f"{cached_response}\n\nüí° _–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∫—ç—à–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞_"
                else:
                    immunity_response = get_immunity_recommendation_template()
                    enhanced_vector_db.cache_response(user_text, immunity_response)
                
                # –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–± –∏–º–º—É–Ω–∏—Ç–µ—Ç–µ
                from immunity_recommendations import IMMUNITY_CORE_PRODUCTS
                immunity_context = []
                for product_info in IMMUNITY_CORE_PRODUCTS:
                    immunity_context.append({
                        "product": product_info["name"],
                        "url": "",  # –ë—É–¥–µ—Ç –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Å—ã–ª–∫–∏
                        "image_id": "",  # –ë—É–¥–µ—Ç –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Å—ã–ª–∫–∏
                        "short_description": product_info["description"]
                    })
                
                return immunity_response, immunity_context
            
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            cached_response = enhanced_vector_db.get_cached_response(user_text)
            if cached_response:
                return f"{cached_response}\n\nüí° _–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∫—ç—à–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞_"
            
            
            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ NLP
            processed_message = nlp_processor.process_message(user_text)
            
            # 3. –£–°–ò–õ–ï–ù–ù–´–ô –ú–ù–û–ì–û–£–†–û–í–ù–ï–í–´–ô –ü–û–ò–°–ö
            search_results = []
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–∏–ª–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞ –¥–ª—è –í–°–ï–• –∑–∞–ø—Ä–æ—Å–æ–≤
            if enhanced_search_engine:
                print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–∏–ª–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞")
                enhanced_results = enhanced_search_engine.enhanced_search(
                    query=processed_message.expanded_query,
                    max_results=8,  # –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
                    min_confidence=0.2  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —à–∏—Ä–æ–∫–æ–≥–æ –æ—Ö–≤–∞—Ç–∞
                )
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç SearchResult
                for er in enhanced_results:
                    search_results.append(SearchResult(
                        chunk=type('Chunk', (), {
                            'product': er.product,
                            'chunk_type': er.chunk_type,
                            'text': er.content,
                            'metadata': er.metadata
                        })(),
                        score=er.relevance_score,
                        source=f"{er.source} ({', '.join(er.strategies_used)})"
                    ))
                
                print(f"üéØ –£—Å–∏–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—à–µ–ª {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            # 4. FALLBACK: –µ—Å–ª–∏ —É—Å–∏–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É
            if not search_results:
                print(f"üîÑ Fallback –∫ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ –ø–æ–∏—Å–∫–∞")
                if self._should_search_immediately(processed_message.intent):
                    filters = self._get_search_filters(processed_message)
                    search_results = enhanced_vector_db.search(
                        query=processed_message.expanded_query,
                        filters=filters,
                        limit=3
                    )
                
                # –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º
                if processed_message.entities:
                    for entity in processed_message.entities:
                        if entity.label == "PRODUCT":
                            product_results = enhanced_vector_db.search_by_product(
                                entity.text, limit=2
                            )
                            search_results.extend(product_results)
                
                # –ü–æ–∏—Å–∫ –ø–æ —Å–ª—É—á–∞—é –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
                if not search_results and processed_message.intent in [
                    Intent.GENERAL_QUESTION, Intent.PRODUCT_SELECTION
                ]:
                    search_results = enhanced_vector_db.search_by_use_case(
                        processed_message.expanded_query, limit=3
                    )
                
                # –û–±—â–∏–π –ø–æ–∏—Å–∫
                if not search_results:
                    search_results = enhanced_vector_db.search(
                        processed_message.expanded_query, limit=2
                    )

            # 5.1. –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤—Å–µ–≥–¥–∞ –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –¥–ª—è –õ–Æ–ë–´–• –∑–∞–ø—Ä–æ—Å–æ–≤ 
            local_context = self._build_local_kb_context(processed_message.expanded_query)
            if local_context:
                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM (–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞)
                local_info = self._build_context_from_local(local_context)
                if local_info and local_info != "NO_INFORMATION_FOUND":
                    context = local_info
                    print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {local_context.count('–ü—Ä–æ–¥—É–∫—Ç: ')})")
                # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback –æ—Ç–≤–µ—Ç
                if not self.api_key:
                    provisional = self._fallback_response(local_context)
                    return provisional
            
            # 6. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            if 'context' not in locals() or not context:
                context = self._build_context(search_results)
            
            # 6.1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if context == "NO_INFORMATION_FOUND":
                # –°–æ–∑–¥–∞–µ–º –≤–µ–∂–ª–∏–≤—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É
                response = (
                    "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n\n"
                    "üí° –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç:\n"
                    "‚Ä¢ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
                    "‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞\n"
                    "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É\n\n"
                    "‚úâÔ∏è –ù–∞–ø–∏—à–∏—Ç–µ –ù–∞—Ç–∞–ª—å–µ ‚Äî –æ–Ω–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–º–æ–∂–µ—Ç!"
                )
                return response
            
            # 7. –ï—Å–ª–∏ —ç—Ç–æ –∂–∞–ª–æ–±–∞ —Å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é, –¥–æ–±–∞–≤–ª—è–µ–º –æ—Å–æ–±—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            if (processed_message.intent == Intent.COMPLAINT or 
                processed_message.sentiment == "negative"):
                context += "\n\n–í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã—Ä–∞–∂–∞–µ—Ç –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ. –ù—É–∂–Ω–æ –ø—Ä–æ—è–≤–∏—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ."
            
            # 7.1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—Å–∏—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å "–≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã"
            all_options_keywords = ["–∫–∞–∫–æ–π –µ—â–µ", "–µ—â–µ –µ—Å—Ç—å", "–ø–æ–º–∏–º–æ —ç—Ç–æ–≥–æ", "—á—Ç–æ –µ—â–µ", "–≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã", "–≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã", "—á—Ç–æ –µ—â–µ –µ—Å—Ç—å", "–∫–∞–∫–∏–µ –µ—â–µ", "–¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã", "–µ—â–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã", "–ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä", "–≤–µ—Å—å –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç"]
            user_text_lower = processed_message.text.lower()
            is_all_options_request = any(keyword in user_text_lower for keyword in all_options_keywords)
            
            if is_all_options_request:
                context += "\n\n–í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –í–°–ï –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤. –†–ï–ö–û–ú–ï–ù–î–£–ô –í–°–ï –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–î–£–ö–¢–´!"
            
            # 8. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            response = self._ask_llm(
                processed_message.text,
                context,
                processed_message.intent
            )
            
            # 9. –ö—ç—à–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            if len(user_text.strip()) > 20:  # –ö—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                enhanced_vector_db.cache_response(user_text, response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

    def _expand_query_with_synonyms(self, query: str) -> str:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –æ–º–µ–≥–∞-3 –∏ –º–∞–≥–Ω–∏—è"""
        query_lower = query.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º—ã –æ–º–µ–≥–∞-3
        for synonym in OMEGA_SYNONYMS:
            if synonym in query_lower:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–∏–Ω–æ–Ω–∏–º—ã –æ–º–µ–≥–∞-3 –∫ –∑–∞–ø—Ä–æ—Å—É
                expanded_terms = " ".join(OMEGA_SYNONYMS)
                return f"{query} {expanded_terms}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º—ã –º–∞–≥–Ω–∏—è
        for synonym in MAGNESIUM_SYNONYMS:
            if synonym in query_lower:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–∏–Ω–æ–Ω–∏–º—ã –º–∞–≥–Ω–∏—è –∫ –∑–∞–ø—Ä–æ—Å—É
                expanded_terms = " ".join(MAGNESIUM_SYNONYMS)
                return f"{query} {expanded_terms}"
        
        return query

    def _build_local_kb_context(self, expanded_query: str) -> Optional[str]:
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º"""
        try:
            # –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –æ–º–µ–≥–∞-3
            expanded_query = self._expand_query_with_synonyms(expanded_query)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if self.smart_search and self.smart_nlp:
                return self._smart_search_context(expanded_query)
            else:
                # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É –ø–æ–∏—Å–∫—É
                return self._fallback_local_search(expanded_query)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ _build_local_kb_context: {e}")
            return None
    
    def _build_context_from_local(self, local_context: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è LLM"""
        if not local_context:
            return "NO_INFORMATION_FOUND"
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è LLM
        lines = local_context.split('\n')
        products = []
        current_product = {}
        
        for line in lines:
            if line.startswith('–ü—Ä–æ–¥—É–∫—Ç: '):
                if current_product:
                    products.append(current_product)
                current_product = {'name': line.replace('–ü—Ä–æ–¥—É–∫—Ç: ', '').strip()}
            elif line.startswith('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: '):
                current_product['category'] = line.replace('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: ', '').strip()
            elif line.startswith('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '):
                current_product['description'] = line.replace('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: ', '').strip()
        
        if current_product:
            products.append(current_product)
        
        if not products:
            return "NO_INFORMATION_FOUND"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è LLM
        formatted_chunks = []
        for product in products:
            chunk = f"–ü—Ä–æ–¥—É–∫—Ç: {product['name']}\n"
            if 'category' in product:
                chunk += f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product['category']}\n"
            if 'description' in product:
                chunk += f"–û–ø–∏—Å–∞–Ω–∏–µ: {product['description']}\n"
            formatted_chunks.append(chunk)
        
        return "\n---\n".join(formatted_chunks)

    def _search_in_kb(self, kb_data: list, terms: list, source: str, found_products: set) -> list:
        """–ü–æ–∏—Å–∫ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        matches = []
        for item in kb_data:
            product = item.get("product", "")
            product_id = item.get("id", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ø–æ–ª—è –Ω–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤
            searchable_fields = {
                "product": item.get("product", ""),
                "description": item.get("description", ""),
                "short_description": item.get("short_description", ""),
                "benefits": "; ".join(item.get("benefits", [])),
                "short_benefits": "; ".join(item.get("short_benefits", [])),
                "composition": item.get("composition", ""),
                "dosage": item.get("dosage", ""),
                "contraindications": item.get("contraindications", ""),
                "category": item.get("category", ""),
            }
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance_score = 0
            matching_fields = []
            
            for field_name, field_text in searchable_fields.items():
                if field_text:
                    matches_in_field = sum(1 for term in terms if term in field_text.lower())
                    if matches_in_field > 0:
                        matching_fields.append(field_name)
                        # –ì–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –≤–µ—Å –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞
                        if field_name == "product":
                            relevance_score += matches_in_field * 10  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—é
                        elif field_name in ["short_description", "benefits"]:
                            relevance_score += matches_in_field * 3
                        else:
                            relevance_score += matches_in_field
            
            if relevance_score > 0 and product_id not in found_products:
                found_products.add(product_id)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ
                category = item.get("category", "")
                form = item.get("form", "")
                short_desc = item.get("short_description", "")
                
                part = (
                    f"–ü—Ä–æ–¥—É–∫—Ç: {product}\n"
                    f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n"
                    f"–§–æ—Ä–º–∞: {form}\n"
                    f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {short_desc}\n"
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {min(0.95, 0.50 + relevance_score * 0.1):.2f}\n"
                    f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source}\n"
                )
                matches.append((relevance_score, part))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        matches.sort(key=lambda x: x[0], reverse=True)
        return [match[1] for match in matches]
    
    def _ask_llm(self, question: str, context: str, intent: Intent) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenAI API"""
        if not self.api_key:
            return self._fallback_response(context)
        
        system_prompt = self._get_system_prompt(intent)
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n{context}\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}"
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                answer = result["choices"][0]["message"]["content"]
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Markdown –≤ HTML –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                answer = self._convert_markdown_to_html(answer)
                
                # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ø–æ–¥–ø–∏—Å—å LLM –Ω–∞ –Ω–∞—à—É
                import re
                answer = re.sub(r'\(–ò—Å—Ç–æ—á–Ω–∏–∫:.*?\)', '', answer)
                answer = answer.strip()
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à—É –ø–æ–¥–ø–∏—Å—å
                answer += "\n\n*üìö –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Aurora*"
                
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —É–±—Ä–∞–Ω–æ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ bot.py
                # answer = self._limit_response_length(answer)
                
                return answer
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API ({response.status_code}): {response.text[:200]}")
                return self._fallback_response(context)
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {e}")
            return self._fallback_response(context)
    
    def _convert_markdown_to_html(self, text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Markdown —Ä–∞–∑–º–µ—Ç–∫—É –≤ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ HTML —Ç–µ–≥–æ–≤"""
        import re
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º **text** –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏)
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º *text* –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º `text` –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏)
        text = re.sub(r'`(.*?)`', r'\1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º _text_ –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±–∏—Ä–∞–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
        text = re.sub(r'_(.*?)_', r'\1', text)
        
        return text
    
    def _generate_follow_up_questions(self, products_info: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
        if not products_info:
            return ""
        
        questions = []
        
        for product_name in products_info.keys():
            product_lower = product_name.lower()
            
            # –í–æ–ø—Ä–æ—Å—ã –æ —Å–æ—Å—Ç–∞–≤–µ
            if "—Å–æ–ª–±–µ—Ä—Ä–∏" in product_lower or "–æ–±–ª–µ–ø–∏—Ö" in product_lower:
                questions.extend([
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–ª—å–∑–µ –æ–±–ª–µ–ø–∏—Ö–∏",
                    "‚Ä¢ –ö–∞–∫–∏–µ –≤–∏—Ç–∞–º–∏–Ω—ã —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–ª–µ–ø–∏—Ö–∞?",
                    "‚Ä¢ –ö–∞–∫ –æ–±–ª–µ–ø–∏—Ö–∞ —É–∫—Ä–µ–ø–ª—è–µ—Ç –∏–º–º—É–Ω–∏—Ç–µ—Ç?"
                ])
            elif "–±–∏—Ç–µ—Ä–æ–Ω" in product_lower or "—Å–≤–µ–∫–ª" in product_lower:
                questions.extend([
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–ª—å–∑–µ —Å–≤–µ–∫–ª—ã",
                    "‚Ä¢ –ö–∞–∫ —Å–≤–µ–∫–ª–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫—Ä–æ–≤—å?",
                    "‚Ä¢ –ö–∞–∫–∏–µ –≤–µ—â–µ—Å—Ç–≤–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–≤–µ–∫–ª–∞?"
                ])
            elif "–∞—Ä–≥–µ–Ω—Ç" in product_lower or "—Å–µ—Ä–µ–±—Ä" in product_lower:
                questions.extend([
                    "‚Ä¢ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–µ—Ä–µ–±—Ä–æ –ø—Ä–æ—Ç–∏–≤ –±–∞–∫—Ç–µ—Ä–∏–π?",
                    "‚Ä¢ –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Å–µ—Ä–µ–±—Ä–∞",
                    "‚Ä¢ –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ª–∏ —Å–µ—Ä–µ–±—Ä–æ –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–º–∞?"
                ])
            
            # –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–¥—É–∫—Ç–µ
            questions.extend([
                f"‚Ä¢ –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Å–æ—Å—Ç–∞–≤–µ {product_name}",
                f"‚Ä¢ –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–Ω–∏–º–∞—Ç—å {product_name}?",
                f"‚Ä¢ –ï—Å—Ç—å –ª–∏ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è —É {product_name}?",
                f"‚Ä¢ –ú–æ–∂–Ω–æ –ª–∏ —Å–æ—á–µ—Ç–∞—Ç—å {product_name} —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏?"
            ])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_questions = list(dict.fromkeys(questions))[:6]
        
        if unique_questions:
            return (
                "\n\nüí° –ú–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ:\n" + 
                "\n".join(unique_questions) +
                "\n\nüí¨ –ü—Ä–æ—Å—Ç–æ —Å–ø—Ä–æ—Å–∏!"
            )
        
        return ""

    def _fallback_response(self, context: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
        if not context or context == "NO_INFORMATION_FOUND" or "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞" in context:
            response = (
                "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n\n"
                "üí° –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç:\n"
                "‚Ä¢ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
                "‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞\n"
                "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É\n\n"
                "‚úâÔ∏è –ù–∞–ø–∏—à–∏—Ç–µ –ù–∞—Ç–∞–ª—å–µ ‚Äî –æ–Ω–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–º–æ–∂–µ—Ç!"
            )
            return response
        
        # –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö
        lines = context.split('\n')
        products = []
        current_product = {}
        
        for line in lines:
            if line.startswith('–ü—Ä–æ–¥—É–∫—Ç: '):
                if current_product:
                    products.append(current_product)
                current_product = {'name': line.replace('–ü—Ä–æ–¥—É–∫—Ç: ', '').strip()}
            elif line.startswith('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: '):
                current_product['category'] = line.replace('–ö–∞—Ç–µ–≥–æ—Ä–∏—è: ', '').strip()
            elif line.startswith('–§–æ—Ä–º–∞: '):
                current_product['form'] = line.replace('–§–æ—Ä–º–∞: ', '').strip()
            elif line.startswith('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '):
                current_product['description'] = line.replace('–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: ', '').strip()
        
        if current_product:
            products.append(current_product)
        
        if not products:
            return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –≤—ã–±–æ—Ä–∞
        if len(products) == 1:
            product = products[0]
            response = f"üåø **{product['name']}**\n\n"
            if 'category' in product:
                response += f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product['category']}\n"
            if 'form' in product:
                response += f"üíä –§–æ—Ä–º–∞: {product['form']}\n"
            if 'description' in product:
                response += f"üìù {product['description']}\n\n"
            response += "üí° –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —Å–æ—Å—Ç–∞–≤–µ, —Å–ø–æ—Å–æ–±–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        else:
            response = f"üîç –ù–∞–π–¥–µ–Ω–æ **{len(products)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤** –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É:\n\n"
            
            for i, product in enumerate(products, 1):
                response += f"**{i}. {product['name']}**\n"
                if 'category' in product:
                    response += f"   üìÇ {product['category']}\n"
                if 'form' in product:
                    response += f"   üíä {product['form']}\n"
                if 'description' in product:
                    response += f"   üìù {product['description'][:100]}...\n"
                response += "\n"
            
            response += "üí° **–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–¥—É–∫—Ç –∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–º:**\n"
            response += "‚Ä¢ –°–æ—Å—Ç–∞–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n"
            response += "‚Ä¢ –°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n"
            response += "‚Ä¢ –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è\n"
            response += "‚Ä¢ –ü–æ–ª–µ–∑–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞"
        
        return response

    def _limit_response_length(self, response: str, max_length: int = None) -> str:
        """–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
        # –ú–µ—Ç–æ–¥ –æ—Ç–∫–ª—é—á–µ–Ω - –≤—Å—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–µ–∑–∞–Ω–∏—è —Ç–µ–ø–µ—Ä—å –≤ bot.py
        return response
    
    def _smart_search_context(self, query: str) -> Optional[str]:
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLP –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
        try:
            # –ü–∞—Ä—Å–∏–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
            parsed_query = self.smart_nlp.parse_query(query)
            
            print(f"üß† –£–º–Ω—ã–π –ø–æ–∏—Å–∫: '{query}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {parsed_query.confidence:.2f})")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            results = self.smart_search.search(query, parsed_query.filters)
            
            if not results:
                print("‚ùå –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                # –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤
                print("üîÑ –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤...")
                results = self.smart_search.search(query)
                
                if not results:
                    print("‚ùå –ü–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Ç–æ–∂–µ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return None
                else:
                    print(f"‚úÖ –ü–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–∞—à–µ–ª {len(results)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —É–º–Ω—ã–º –ø–æ–∏—Å–∫–æ–º")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            context_parts = []
            
            for result in results:
                part = f"–ü—Ä–æ–¥—É–∫—Ç: {result.product_name}\n"
                part += f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result.category}\n"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ —Å–≤–æ–π—Å—Ç–≤
                if result.properties:
                    part += f"–°–≤–æ–π—Å—Ç–≤–∞: {', '.join(result.properties[:3])}\n"
                
                if result.indications:
                    part += f"–ü–æ–∫–∞–∑–∞–Ω–∏—è: {', '.join(result.indications[:2])}\n"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                original = result.original_data.get('original_data', {})
                if original.get('short_description'):
                    part += f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {original['short_description']}\n"
                
                context_parts.append(part)
            
            return "\n---\n".join(context_parts)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def _fallback_local_search(self, expanded_query: str) -> Optional[str]:
        """Fallback –∫ —Å—Ç–∞—Ä–æ–º—É –ª–æ–∫–∞–ª—å–Ω–æ–º—É –ø–æ–∏—Å–∫—É"""
        try:
            import json
            # –ò—â–µ–º –ø–æ –∑–Ω–∞—á–∏–º—ã–º —Å–ª–æ–≤–∞–º (–¥–ª–∏–Ω–æ–π –±–æ–ª—å—à–µ 2 —Å–∏–º–≤–æ–ª–æ–≤, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞)
            stop_words = {"—Å", "–∏", "–¥–ª—è", "–Ω–∞", "–æ—Ç", "–ø–æ", "–≤", "–∫", "–∏–∑", "–¥–æ", "–∑–∞", "–ø—Ä–∏", "–ø—Ä–æ", "–±–µ–∑", "–ø–æ–¥", "–Ω–∞–¥", "–æ", "–æ–±", "—á—Ç–æ", "–∫–∞–∫", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "who", "what", "where", "when", "how", "with", "and", "for", "the", "of", "to", "in", "a", "an"}
            terms = [t.strip().lower() for t in expanded_query.split() 
                    if len(t.strip()) > 2 and t.strip().lower() not in stop_words]
            if not terms:
                return None
            
            matches = []
            found_products = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤
            
            # –ü–æ–∏—Å–∫ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            try:
                with open("knowledge_base.json", "r", encoding="utf-8") as f:
                    kb_main = json.load(f)
                matches.extend(self._search_in_kb(kb_main, terms, "knowledge_base.json", found_products))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è knowledge_base.json: {e}")
            
            # –ü–æ–∏—Å–∫ –≤ –Ω–æ–≤–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            try:
                with open("knowledge_base_new.json", "r", encoding="utf-8") as f:
                    kb_new = json.load(f)
                matches.extend(self._search_in_kb(kb_new, terms, "knowledge_base_new.json", found_products))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è knowledge_base_new.json: {e}")
            
            if matches:
                return "\n---\n".join(matches)
            return None
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def _is_immunity_query(self, query: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –æ –∏–º–º—É–Ω–∏—Ç–µ—Ç–µ"""
        immunity_keywords = [
            '–∏–º–º—É–Ω–∏—Ç–µ—Ç', '–∏–º–º—É–Ω–Ω', 'immunity', 
            '–¥–ª—è —É–∫—Ä–µ–ø–ª–µ–Ω–∏—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞', '—É–∫—Ä–µ–ø–ª–µ–Ω–∏—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞',
            '–¥–ª—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞', '—É–∫—Ä–µ–ø–∏—Ç—å –∏–º–º—É–Ω–∏—Ç–µ—Ç', '–ø–æ–≤—ã—Å–∏—Ç—å –∏–º–º—É–Ω–∏—Ç–µ—Ç',
            '–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –∏–º–º—É–Ω–∏—Ç–µ—Ç', '–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞',
            '–∑–∞—â–∏—Ç–Ω—ã–µ —Å–∏–ª—ã', '–∑–∞—â–∏—Ç–Ω—ã—Ö —Å–∏–ª', '–∑–∞—â–∏—Ç–∞ –æ—Ä–≥–∞–Ω–∏–∑–º–∞',
            '—Å–æ–ø—Ä–æ—Ç–∏–≤–ª—è–µ–º–æ—Å—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–º–∞', '–ø–æ–≤—ã—Å–∏—Ç—å —Å–æ–ø—Ä–æ—Ç–∏–≤–ª—è–µ–º–æ—Å—Ç—å'
        ]
        
        query_lower = query.lower().strip()
        return any(keyword in query_lower for keyword in immunity_keywords)

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
enhanced_llm = EnhancedLLM()
